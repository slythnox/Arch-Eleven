{
  "activeBackend": "generic",
  "backends": {
    "ollama": {
      "type": "http",
      "endpoint": "http://localhost:11434/api/generate",
      "timeout": 30000,
      "description": "Ollama local LLM server"
    },
    "llamacpp": {
      "type": "http",
      "endpoint": "http://localhost:8080/completion",
      "timeout": 30000,
      "description": "llama.cpp HTTP server"
    },
    "generic": {
      "type": "http",
      "endpoint": "http://localhost:11434/api/generate",
      "timeout": 30000,
      "description": "Generic HTTP API endpoint"
    }
  },
  "models": {
    "default": {
      "name": "phi3:mini",
      "description": "Default conversational model (Microsoft Phi-3)",
      "parameters": {
        "temperature": 0.7,
        "maxTokens": 500
      }
    },
    "code": {
      "name": "codellama:7b",
      "description": "Code generation and analysis",
      "parameters": {
        "temperature": 0.3,
        "maxTokens": 1500
      }
    },
    "fast": {
      "name": "qwen2.5:1.5b",
      "description": "Fast, lightweight model for quick responses",
      "parameters": {
        "temperature": 0.8,
        "maxTokens": 300
      }
    },
    "creative": {
      "name": "gemma2:9b",
      "description": "Creative writing and storytelling",
      "parameters": {
        "temperature": 0.9,
        "maxTokens": 1000
      }
    }
  }
}
